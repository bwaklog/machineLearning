{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a080380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(f\"Tensorflow Version:{tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b4142",
   "metadata": {},
   "source": [
    "We are going to use `Fashion MNIST dataaset` for grayscale 28x28 pixel clothing images. They are labeled 0->10\n",
    " 0. T-shirt/top\n",
    " 1. Trouser\n",
    " 2. Pullover\n",
    " 3. Dress\n",
    " 4. Coat\n",
    " 5. Sandals\n",
    " 6. Shirt\n",
    " 7. Sneakers\n",
    " 8. Bag\n",
    " 9. Ankle boots\n",
    " \n",
    "The dataset is available in the `tf.keras.dataset` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012fa307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "fmnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7810e2c5",
   "metadata": {},
   "source": [
    "Calling `load_data()` on this object will give 2 tuples with two lists each. These will be training and testing values for the graphics that contain the clothing items and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e20f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8), array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)), (array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8), array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)))\n"
     ]
    }
   ],
   "source": [
    "# Displaying the fmnist dataset. Shows 2 tuples with 2 lists each\n",
    "print(fmnist.load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b3f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We store these lists in variables\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a962df55",
   "metadata": {},
   "source": [
    "What would these look like?\n",
    "\n",
    "We can print a training image(both as an image and a numpy array), and a training label to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1caeb2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 3\n",
      "\n",
      "IMAGE PIXEL ARRAY:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0  68  89  15  68  92  20   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  13 169 201 188 225 185 187 175 119   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 158 239 188 161 167 142 191 199 193   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 158 227 219 191 186 146 207 224 219  48   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 171 228 235 227 202 217 231 231 226  95   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 182 227 235 234 245 245 234 235 233 168   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 253 184 215 244 231 229 255 138 193 215   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 255  93 190 254 231 223 255  64 166 254   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   3 255  88 180 254 228 222 255  67 128 255   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  43 255 112 201 252 230 228 255 150 131 235  17   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  67 196 212 228 235 231 230 240 224 203 224  75   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 151 205 235 231 233 231 235 234 237 223 218 155   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  82 114 216 236 231 234 233 234 240 192 118  24   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 199 246 231 236 235 234 251 159   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 254 241 232 237 234 235 246 218   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 230 239 231 239 233 236 242 209   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   6 238 238 233 239 235 238 239 228   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  49 248 236 236 240 236 239 237 241   4   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  81 254 236 233 240 236 239 237 247  37   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 127 253 238 233 239 235 241 235 254  66   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 174 250 240 234 240 238 240 236 254 119   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 201 247 240 236 238 240 240 237 254 175   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 197 247 240 235 239 237 241 239 252 219   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 217 246 243 237 240 249 242 239 250 206   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 219 226 224 237 237 222 230 237 212 203   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  14 199 198 194 185 207 158 194 237 181 217  37   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  39 199 164 175 205 216 176 205 216 135 215  43   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  66  10   0   3   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x281511cc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You can put between 0 to 59999 here - which image\n",
    "index = 2004\n",
    "\n",
    "# Set number of characters per row when printing\n",
    "np.set_printoptions(linewidth=320)\n",
    "\n",
    "# Print the label and image\n",
    "print(f'LABEL: {training_labels[index]}')\n",
    "print(f'\\nIMAGE PIXEL ARRAY:\\n {training_images[index]}')\n",
    "\n",
    "# visualize the image\n",
    "plt.imshow(training_images[index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0943e9f9",
   "metadata": {},
   "source": [
    "Here each pixel value is between 0 and 255. For **neural networks** especially in _image processing_, it is always a good practice to scale the values between 0 and 1. This process is called _**normalization**_ and we can normalize an array without looping by doing the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8399bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values of the train and test images\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87811110",
   "metadata": {},
   "source": [
    "## Desigining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "735d4a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "# Build the classification model\n",
    "model = keras.models.Sequential([keras.layers.Flatten(),\n",
    "                                 keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                 keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e867f0",
   "metadata": {},
   "source": [
    "**Sequential:** Defines a sequence of layers in the neural network.\n",
    "\n",
    "**Flatten:** The images are 28x28 pixel matrices. Flatten takes the 2D              square and turns it into a 1D array.\n",
    "\n",
    "**Dense:** Adds a layer of neurons. Each layer of neuraons needs an `activation function` to tell them what to do.\n",
    "\n",
    "**ReLU:** It passes values 0 or greater to the next layer in the network\n",
    "\n",
    "```python\n",
    "if x > 0:\n",
    "    returnx\n",
    "else:\n",
    "    return 0\n",
    "```\n",
    "\n",
    "**Softmax:** takes a list of values and scales these to the sum of all the elements whill be equal to 1. When applied to model outputs, you can think of the scaled values as the probability for the class. For example, in the calssification model which has 10 units in the output dense layer, having the highest value at index=4 means that the model is _MOST_ confident that the input clothing is a COAT. If the index=5, then it is sandals and so fourth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed8fa97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input to softmax function: [[1. 3. 4. 2.]]\n",
      "output of softmax fucntion: [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
      "sum of outputs: 1.0\n",
      "class with highest probability: 2\n"
     ]
    }
   ],
   "source": [
    "# Declare sample inputs and convert to a tensor\n",
    "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print(f'input to softmax function: {inputs.numpy()}')\n",
    "\n",
    "# Feed the inputs to a softmax activation function\n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'output of softmax fucntion: {outputs.numpy()}')\n",
    "\n",
    "# Get the sum of all values after the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "# Get the index with highest value\n",
    "prediction = np.argmax(outputs)\n",
    "print(f'class with highest probability: {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828f33b",
   "metadata": {},
   "source": [
    "This model is untrainined. \n",
    "\n",
    "Now that the model is defined, we have to build the mode. We can compile it with an optimizer and a loss function. Then call `model.fit()` to fit the training data to your training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7416e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2319 - accuracy: 0.9126\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2228 - accuracy: 0.9162\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2162 - accuracy: 0.9183\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2098 - accuracy: 0.9204\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2052 - accuracy: 0.9232\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1977 - accuracy: 0.9262\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1931 - accuracy: 0.9273\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1898 - accuracy: 0.9278\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1840 - accuracy: 0.9311\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1794 - accuracy: 0.9332\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1750 - accuracy: 0.9354\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1701 - accuracy: 0.9367\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1643 - accuracy: 0.9383\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1599 - accuracy: 0.9399\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1578 - accuracy: 0.9399\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1544 - accuracy: 0.9414\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1509 - accuracy: 0.9442\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1492 - accuracy: 0.9441\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1465 - accuracy: 0.9447\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1397 - accuracy: 0.9479\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1386 - accuracy: 0.9482\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1370 - accuracy: 0.9493\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1330 - accuracy: 0.9500\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1309 - accuracy: 0.9510\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1289 - accuracy: 0.9513\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1241 - accuracy: 0.9523\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1246 - accuracy: 0.9530\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1213 - accuracy: 0.9539\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1184 - accuracy: 0.9546\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1141 - accuracy: 0.9568\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1152 - accuracy: 0.9564\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1112 - accuracy: 0.9583\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1101 - accuracy: 0.9585\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1088 - accuracy: 0.9589\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1034 - accuracy: 0.9611\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1038 - accuracy: 0.9609\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1020 - accuracy: 0.9621\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1004 - accuracy: 0.9615\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0972 - accuracy: 0.9633\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0981 - accuracy: 0.9630\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0953 - accuracy: 0.9639\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0936 - accuracy: 0.9646\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0904 - accuracy: 0.9663\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0924 - accuracy: 0.9660\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0861 - accuracy: 0.9671\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0918 - accuracy: 0.9652\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0844 - accuracy: 0.9682\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0865 - accuracy: 0.9678\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0863 - accuracy: 0.9675\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0829 - accuracy: 0.9684\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0823 - accuracy: 0.9692\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0824 - accuracy: 0.9692\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0813 - accuracy: 0.9695\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0806 - accuracy: 0.9702\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0771 - accuracy: 0.9708\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0760 - accuracy: 0.9716\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0736 - accuracy: 0.9726\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0766 - accuracy: 0.9710\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0715 - accuracy: 0.9733\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0733 - accuracy: 0.9722\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0705 - accuracy: 0.9736\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0686 - accuracy: 0.9742\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0694 - accuracy: 0.9741\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0671 - accuracy: 0.9752\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0679 - accuracy: 0.9746\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0676 - accuracy: 0.9748\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0649 - accuracy: 0.9755\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0667 - accuracy: 0.9750\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0652 - accuracy: 0.9761\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0625 - accuracy: 0.9758\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0632 - accuracy: 0.9766\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0615 - accuracy: 0.9768\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0624 - accuracy: 0.9769\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0633 - accuracy: 0.9761\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0589 - accuracy: 0.9780\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0614 - accuracy: 0.9769\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0574 - accuracy: 0.9789\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0580 - accuracy: 0.9782\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0574 - accuracy: 0.9792\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0586 - accuracy: 0.9779\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0538 - accuracy: 0.9797\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0575 - accuracy: 0.9779\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0516 - accuracy: 0.9808\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0543 - accuracy: 0.9795\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0556 - accuracy: 0.9791\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0519 - accuracy: 0.9802\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0542 - accuracy: 0.9798\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0520 - accuracy: 0.9809\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0512 - accuracy: 0.9808\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0541 - accuracy: 0.9800\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0492 - accuracy: 0.9813\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0506 - accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0495 - accuracy: 0.9814\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0491 - accuracy: 0.9817\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0503 - accuracy: 0.9807\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0469 - accuracy: 0.9830\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0497 - accuracy: 0.9814\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0473 - accuracy: 0.9823\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0465 - accuracy: 0.9832\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0451 - accuracy: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29e437e80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.optimizers.legacy.Adam(),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c516ea1",
   "metadata": {},
   "source": [
    "Once training is complete, we can see an `accuracy` value at the end of the final epoch. If its 0.9116, that means your neural network is about 91.16% accurate in calssifying the training data. \n",
    "\n",
    "---\n",
    "\n",
    "Now we are going to test it with the test images and labels. We can use call the `model.evaluate()` with the test data as inputs and it will report back the `loss` and `accuracy` of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c33c7411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8867 - accuracy: 0.8817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.886705756187439, 0.8816999793052673]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalluate the model on unseen data -> test_images, test_labels\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aeb3f0",
   "metadata": {},
   "source": [
    "### Saving the Model\n",
    "Models saved in this format can be restored using `tf.keras.models.load_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36b1a5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fmnist_saved_model/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fmnist_saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('fmnist_saved_model/my_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
